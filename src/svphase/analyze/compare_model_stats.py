import pandas as pd
import numpy as np
import os

def get_model_and_version(model_stat):
	fname = os.path.basename(model_stat).split('.')
	return fname[0], '.'.join(fname[1:3])

def main(model_stats):
	
	df = []
	for stat in model_stats:
		# extract model names
		model, version = get_model_and_version(stat)
		statdf = pd.read_csv(stat, sep='\t', header=0, index_col=None, na_values=['',])
		statdf['model'] = model
		statdf['version'] = version
		df.append(statdf)
	
	df = pd.concat(df, axis=0)
	gstat = df.groupby(['model','version'])
	average = gstat.apply(lambda d:np.average(d.loc[pd.isnull(d['inner_fold']),'test_accuracy']))
	std = gstat.apply(lambda d:np.std(d.loc[pd.isnull(d['inner_fold']),'test_accuracy']))
	average.name = 'avg'
	std.name = 'std'
	t = pd.concat([average, std], axis=1)	
	print t
	return t

def main_per_class(model_stats):
	df = []
	for stat in model_stats:
		# extract model names
		model, version = get_model_and_version(stat)
		statdf = pd.read_csv(stat, sep='\t', header=0, index_col=None, na_values=['',])
		statdf['model'] = model
		statdf['version'] = version
		df.append(statdf)
	
	df = pd.concat(df, axis=0)
	df = df.loc[pd.isnull(df['inner_fold']),:]
	#Expect cpred: and tpred: columns
	tpred_c = [c for c in df.columns if c.startswith('tpred:')]
	cpred_c = [c for c in df.columns if c.startswith('cpred:')]
	for c,t in zip(cpred_c, tpred_c):
		df['ac'+c] = df[c]/df[t].astype(float)
	accpred_c = ['ac'+c for c in cpred_c]
	gstats = df.groupby(['model','version'])
	average = gstats.apply(lambda d:d.loc[:,accpred_c].apply(np.average).rename(lambda c:'avg'+c[7:]))
	average.name  = 'avg'
	std = gstats.apply(lambda d:d.loc[:,accpred_c].apply(np.std).rename(lambda c:'std'+c[7:]))
	std.name  = 'std'
	total = gstats.apply(lambda d:d.loc[:,tpred_c].sum())
	total.name = 'total'
	t = pd.concat([average,std,total], axis=1)
	print t
	#print average
	return t

if __name__=='__main__':
	import argparse
	
	parser = argparse.ArgumentParser(description="Compares test performance between different models")
	parser.add_argument('--per-class', dest='pclass', action='store_true', default=False, help="Output avg. std. test accurcies per class")
	parser.add_argument('model_stats', nargs='+', help="Stat files generated by each model")

	args = parser.parse_args()

	if args.pclass:
		main_per_class(args.model_stats)
	else:
		main(args.model_stats)
